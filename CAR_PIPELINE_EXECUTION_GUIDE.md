# Car DB â†’ Kafka â†’ Spark â†’ Inventory DB íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê°€ì´ë“œ

## ì‹¤í–‰ ìˆœì„œ ìš”ì•½ (Docker â†’ Kubernetes íë¦„)

### 1. **MariaDB ì¤€ë¹„:** ì™¸ë¶€ MariaDB(172.16.11.114:3307)ë¥¼ ê¸°ë³¸ ì‚¬ìš©
**ë¡œì»¬ StatefulSetì€ í…ŒìŠ¤íŠ¸ìš©**
- **Secret ìƒì„±** â†’ `kubectl apply -f k8s/mariadb-secret.yaml`
- **StatefulSet ë°°í¬** (í•„ìš” ì‹œ) â†’ `kubectl apply -f k8s/mariadb-statefulset.yaml`
- **Pod/ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸** â†’ `kubectl get pods,svc -l app=mariadb`
- **ì™¸ë¶€ DB ì ‘ì† í…ŒìŠ¤íŠ¸** â†’ `mysql -h 172.16.11.114 -P 3307 -u root -p`

### 2. **Kafka ì¤€ë¹„:** Kafka StatefulSetê³¼ Connectê°€ ë°°í¬ë˜ì–´ ìˆë‹¤ëŠ” ê°€ì •
- **Pod ìƒíƒœ í™•ì¸** â†’ `kubectl get pods -l app=kafka`
- **car.uservehicle í† í”½ ìƒì„±/í™•ì¸** â†’ Kafka CLI ë˜ëŠ” REST APIë¡œ í™•ì¸
- **car.driving_session í† í”½ ìƒì„±/í™•ì¸** â†’ ë™ì¼

### 3. **Spark ì´ë¯¸ì§€ ë¹Œë“œ:** spark-stream/Dockerfile ê¸°ë°˜ìœ¼ë¡œ spark-stream:local ìƒì„±
**Kafka/MariaDB ì»¤ë„¥í„° JARê³¼ stream_processor_car.py í¬í•¨**
```bash
# í˜„ì¬ í´ë”ì—ì„œ ë¹Œë“œ (Dockerfileì´ ì´ë¯¸ ìˆìŒ)
docker build -t spark-stream:local .
docker images | grep spark-stream
```

### 4. **Airflow ì´ë¯¸ì§€ ë¹Œë“œ ë° ë°°í¬:** airflow-k8s/Dockerfileë¡œ airflow-k8s:local ë¹Œë“œ
```bash
# airflow ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace airflow

# Secret/ConfigMap ìƒì„±
kubectl apply -f k8s/mariadb-secret.yaml

# Helmìœ¼ë¡œ Airflow ì„¤ì¹˜ (values.local.yaml ì‚¬ìš©)
helm repo add apache-airflow https://airflow.apache.org
helm install airflow apache-airflow/airflow \
  --namespace airflow \
  --values k8s/values.local.yaml \
  --set images.airflow.repository=airflow-k8s \
  --set images.airflow.tag=local

# Web UI í™•ì¸: http://localhost:30080
```

### 5. **Car DB Source Connector:** k8s/car-db-connector.jsonì„ REST APIë¡œ ë“±ë¡
```bash
# Kafka Connect REST APIë¡œ ë“±ë¡
curl -X POST -H "Content-Type: application/json" \
  --data @k8s/car-db-connector.json \
  http://kafka-connect-service:8083/connectors

# ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ car_db_producer.pyë¡œ ì§ì ‘ ë©”ì‹œì§€ ì „ì†¡ ê°€ëŠ¥
docker-compose exec spark-worker python final_pj/car_db_producer.py
```

### 6. **Airflow DAG í™œì„±í™”:** k8s_spark_stream_dag_car DAGë¥¼ í™œì„±í™”
```bash
# Airflow Web UIì—ì„œ unpause (http://localhost:30080)
# ë˜ëŠ” CLIë¡œ í™œì„±í™”
kubectl exec -n airflow deployment/airflow-webserver -- airflow dags unpause k8s_spark_stream_dag_car

# 1ë¶„ë§ˆë‹¤ Spark ìŠ¤íŠ¸ë¦¬ë° ì‘ì—… ì‹¤í–‰ í™•ì¸
kubectl get pods -n airflow --watch
```

### 7. **ëª¨ë¸ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ë°°í¬:** model-service/Dockerfileë¡œ ë¹Œë“œ (ì„ íƒì‚¬í•­)
```bash
# í˜„ì¬ í”„ë¡œì íŠ¸ì—ëŠ” ëª¨ë¸ ì„œë¹„ìŠ¤ê°€ ë³„ë„ë¡œ ë¶„ë¦¬ë˜ì–´ ìˆìŒ
# í•„ìš”ì‹œ model-service í´ë”ì—ì„œ ë¹Œë“œ
cd model-service
docker build -t model-service:local .
kubectl apply -f ../k8s/model-service-deployment.yaml
```

### 8. **í…ŒìŠ¤íŠ¸ & ë¬¸ì œ í•´ê²°:**
- **Kafka ë©”ì‹œì§€ ì†¡ìˆ˜ì‹  í™•ì¸** â†’ `kubectl logs -l app=kafka-connect`
- **MariaDB í…Œì´ë¸” ì¡°íšŒ** â†’ `kubectl exec mariadb-pod -- mysql -u root inventory_db -e "SELECT * FROM uservehicle LIMIT 5"`
- **Spark ìŠ¤íŠ¸ë¦¬ë° ë¡œê·¸** â†’ `kubectl logs -n airflow -l dag_id=k8s_spark_stream_dag_car`

### 9. **start_car_pipeline.sh:** ìœ„ ê³¼ì •ì„ ì¼ê´„ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
```bash
# ë¡œì»¬ Docker Compose í™˜ê²½ì—ì„œ ì‹¤í–‰
./start_car_pipeline.sh
```

### 10. **ë¶€ë¡:** ì£¼ìš” íŒŒì¼ ì„¤ëª…
- **DAG**: `dags/k8s_spark_stream_dag_car.py` - Car DB íŒŒì´í”„ë¼ì¸ ì›Œí¬í”Œë¡œìš°
- **Spark ìŠ¤í¬ë¦½íŠ¸**: `final_pj/stream_processor_car.py` - ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
- **í”„ë¡œë“€ì„œ**: `final_pj/car_db_producer.py` - ìˆ˜ë™ ë°ì´í„° ì „ì†¡
- **ì´ˆê¸°í™”**: `final_pj/init_uservehicle.py` - ì´ˆê¸° ë°ì´í„° ë³µì‚¬

---

## Docker â†’ Kubernetes íë¦„ ì„¤ëª…

### **Dockerë¶€í„° ì‹œì‘í•˜ëŠ” ì´ìœ :**
ëª¨ë“  ì„œë¹„ìŠ¤(Spark ìŠ¤íŠ¸ë¦¬ë°, Airflow, ëª¨ë¸ ì˜ˆì¸¡)ê°€ **Docker ì´ë¯¸ì§€ë¡œ íŒ¨í‚¤ì§•**ë˜ì–´ ìˆì–´ì•¼ Kubernetes ë°°í¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### **Docker í•µì‹¬ í¬ì¸íŠ¸:**
- `docker build -t spark-stream:local .`ì²˜ëŸ¼ ê° ì„œë¹„ìŠ¤ë³„ Dockerfileë¡œ ì´ë¯¸ì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤
- ì´ë¯¸ì§€ì—ëŠ” ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ì™€ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í¬í•¨í•´ **í™˜ê²½ ì°¨ì´ ì œê±°**
- ë¹Œë“œ í›„ `docker images | grep spark-stream` ë“±ìœ¼ë¡œ ìƒì„± ìƒíƒœ í™•ì¸

### **Kubernetes ë‹¨ê³„:**
- ì¤€ë¹„ëœ ì´ë¯¸ì§€ë¥¼ `kubectl apply`ë‚˜ Helmìœ¼ë¡œ ë°°í¬
- MariaDB, Kafka, Airflow, ëª¨ë¸ ì„œë¹„ìŠ¤ ë“± ëª¨ë“  ì›Œí¬ë¡œë“œê°€ **YAML/Helm ì°¨íŠ¸ë¡œ ì •ì˜**
- **SecretÂ·ConfigMap**ìœ¼ë¡œ ë¯¼ê°ì •ë³´ì™€ ì„¤ì • ì „ë‹¬, **ìŠ¤ì¼€ì¤„ë§Â·ì˜¤í† ë¦¬ì»¤ë²„ë¦¬ëŠ” K8sê°€ ë‹´ë‹¹**

### **ì „ì²´ íë¦„ ì •ë¦¬:**
1. **Dockerë¡œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë§Œë“ ë‹¤**
2. **í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ì°¸ì¡°í•˜ëŠ” Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ì ìš©í•œë‹¤**
3. **Airflow DAGì´ Spark Podë¥¼ ë„ì›Œ Kafkaâ†’MariaDB ì²˜ë¦¬ë¥¼ ìˆ˜í–‰**
4. **ë¬¸ì œ ë°œìƒ ì‹œ kubectl logs ëª…ë ¹ìœ¼ë¡œ ê° ë ˆì´ì–´ë¥¼ ì ê²€**

---

## ìš©ì–´ ì„¤ëª… (docker_pipeline í´ë” ê¸°ì¤€)

- **Pod**: Kubernetesì—ì„œ ê°€ì¥ ì‘ì€ ë°°í¬ ë‹¨ìœ„. ì»¨í…Œì´ë„ˆ(ë“¤)ì™€ ì €ì¥ì†Œ, ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ ë¬¶ì€ ì‹¤í–‰ ë‹¨ìœ„ë¡œ, Spark ì‘ì—… Pod, ëª¨ë¸ ì„œë¹„ìŠ¤ Pod ë“± ëª¨ë“  ì›Œí¬ë¡œë“œê°€ Pod í˜•íƒœë¡œ ëœ¹ë‹ˆë‹¤.

- **Deployment**: ë™ì¼í•œ Podë¥¼ ì›í•˜ëŠ” ìˆ˜ë§Œí¼ ìœ ì§€/ë¡¤ë§ì—…ë°ì´íŠ¸í•˜ëŠ” K8s ë¦¬ì†ŒìŠ¤. ëª¨ë¸ ì„œë¹„ìŠ¤ì²˜ëŸ¼ ì§€ì† ì‹¤í–‰ì´ í•„ìš”í•œ ì•±ì— ì‚¬ìš©í•©ë‹ˆë‹¤.

- **StatefulSet**: ìƒíƒœë¥¼ ê°€ì§„ Podë¥¼ ê³ ì • ì´ë¦„/ìŠ¤í† ë¦¬ì§€ë¡œ ê´€ë¦¬í•˜ëŠ” ë¦¬ì†ŒìŠ¤. MariaDB ê°™ì€ DBì— ì‚¬ìš©í•©ë‹ˆë‹¤.

- **Service**: Podì— ì•ˆì •ì ì¸ ì ‘ê·¼ ì£¼ì†Œë¥¼ ì œê³µí•˜ëŠ” K8s ì˜¤ë¸Œì íŠ¸. ClusterIP/NodePort ë“±ì„ í†µí•´ MariaDB, Airflow Web, Kafka ë“±ì„ ë…¸ì¶œí•©ë‹ˆë‹¤.

- **ConfigMap**: í™˜ê²½ì„¤ì •, DAG íŒŒì¼ ë“± ë¯¼ê°í•˜ì§€ ì•Šì€ ë°ì´í„°ë¥¼ K8s ë¦¬ì†ŒìŠ¤ë¡œ ì €ì¥. Airflow DAG/Pod í…œí”Œë¦¿ì„ ConfigMapìœ¼ë¡œ ì£¼ì…í•©ë‹ˆë‹¤.

- **Secret**: ë¹„ë°€ë²ˆí˜¸Â·í‚¤ ê°™ì€ ë¯¼ê° ì •ë³´ ì €ì¥. ì˜ˆ) mariadb-secretì— DB ë£¨íŠ¸ ë¹„ë°€ë²ˆí˜¸, Airflow Fernet í‚¤.

- **Helm**: K8s íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €. ì—¬ëŸ¬ ë¦¬ì†ŒìŠ¤ë¥¼ í…œí”Œë¦¿í™”í•œ ì°¨íŠ¸ë¥¼ `helm install`ë¡œ í•œ ë²ˆì— ë°°í¬. AirflowëŠ” ê³µì‹ Helm ì°¨íŠ¸ë¥¼ values.local.yamlê³¼ í•¨ê»˜ ì‚¬ìš©.

- **KubernetesPodOperator**: Airflowì—ì„œ K8s Podë¥¼ ì§ì ‘ ìƒì„±í•´ ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ì˜¤í¼ë ˆì´í„°. DAGê°€ Spark ìŠ¤íŠ¸ë¦¬ë° Podë¥¼ ë„ìš°ëŠ” ë° ì‚¬ìš©.

- **Kafka Connect**: Kafkaì™€ ì™¸ë¶€ ì‹œìŠ¤í…œ(DB ë“±)ì„ ì—°ê²°í•˜ëŠ” í”„ë ˆì„ì›Œí¬. Debezium Connectorë¥¼ REST APIë¡œ ë“±ë¡í•˜ë©´ DBâ†’Kafka ë™ê¸°í™”.

- **JDBC URL**: Sparkê°€ MariaDBì— ì“°ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” í‘œì¤€ DB ì ‘ì† ë¬¸ìì—´ (`jdbc:mariadb://172.16.11.114:3307/inventory_db?sessionVariables=sql_mode='ANSI_QUOTES'`).

- **Checkpoint**: Spark Structured Streamingì´ ì§„í–‰ ìƒíƒœë¥¼ `spark_checkpoints/` ê²½ë¡œì— ì €ì¥í•´ ì¬ì‹œì‘ ì‹œ ì´ì–´ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê¸°ëŠ¥. docker_pipeline/spark_checkpoints/car_db_to_inventory_db ì— ì €ì¥ë©ë‹ˆë‹¤.

---

## AWS ì „í™˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)

### **ë¡œì»¬ â†’ AWS í™˜ê²½ ë³€ê²½ì‚¬í•­:**
- [ ] MariaDB: ì™¸ë¶€ RDS ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½ (172.16.11.114 â†’ RDS ì—”ë“œí¬ì¸íŠ¸)
- [ ] Kafka: ë¡œì»¬ Kafka â†’ Amazon MSKë¡œ ë³€ê²½
- [ ] Spark: ë¡œì»¬ ì‹¤í–‰ â†’ Amazon EMR ë˜ëŠ” EKSì—ì„œ ì‹¤í–‰
- [ ] Airflow: ë¡œì»¬ â†’ Amazon MWAAë¡œ ë³€ê²½
- [ ] Secret: AWS Secrets Managerë¡œ ë³€ê²½
- [ ] Storage: ë¡œì»¬ ë³¼ë¥¨ â†’ Amazon EFS/S3ë¡œ ë³€ê²½

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ Car DB íŒŒì´í”„ë¼ì¸ì„ ë‹¨ê³„ë³„ë¡œ êµ¬ì¶•í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€
