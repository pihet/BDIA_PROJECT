from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import requests

# âœ… ì„œë¹„ìŠ¤ ì£¼ì†Œ (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •ë˜ì–´ ìˆìŒ)
FLINK_GATEWAY_URL = "http://sql-gateway-service-20.flink.svc.cluster.local:8083"

def submit_flink_sql(**context):
    # Airflow 3.0 ëŒ€ì‘: execution_date ëŒ€ì‹  logical_date ì‚¬ìš©
    exec_date = context.get('logical_date')
    print(f"ğŸš€ ìŠ¤ì¼€ì¤„ë§ ì‹¤í–‰ ì‹œê°„(UTC): {exec_date}")
    print(f"Connecting to Flink Gateway at: {FLINK_GATEWAY_URL}")
    
    # 1. ì„¸ì…˜ ìƒì„±
    session_url = f"{FLINK_GATEWAY_URL}/v1/sessions"
    headers = {"Content-Type": "application/json"}
    # ì„¸ì…˜ ì´ë¦„ì— ì‹¤í–‰ ì‹œê°„ì„ ë¶™ì—¬ì„œ êµ¬ë¶„í•˜ê¸° ì‰½ê²Œ í•¨
    session_name = f"scheduler_test_{exec_date}"
    
    resp = requests.post(session_url, json={"sessionName": session_name}, headers=headers)
    
    if resp.status_code != 200:
        raise Exception(f"Session creation failed: {resp.text}")

    session_handle = resp.json()['sessionHandle']
    print(f"âœ… Session Created: {session_handle}")

    # 2. SQL ì‹¤í–‰
    sql = "SELECT 'Scheduler Test Success'"
    statement_url = f"{FLINK_GATEWAY_URL}/v1/sessions/{session_handle}/statements"
    resp = requests.post(statement_url, json={"statement": sql}, headers=headers)
    
    if resp.status_code == 200:
        op_handle = resp.json()['operationHandle']
        print(f"âœ… SQL Submitted. Handle: {op_handle}")
    else:
        raise Exception(f"SQL Submit Failed: {resp.text}")

with DAG(
    'flink_schedule_final_test',  # DAG ID
    start_date=datetime(2023, 1, 1), # ê³¼ê±° ë‚ ì§œ (í•„ìˆ˜)
    schedule="*/5 * * * *",          # 5ë¶„ë§ˆë‹¤ ì‹¤í–‰
    catchup=False,                   # ë°€ë¦° ì‘ì—… ì‹¤í–‰ ì•ˆ í•¨
    tags=['test', 'flink', 'v3'],
) as dag:

    run_task = PythonOperator(
        task_id='run_every_5_min',
        python_callable=submit_flink_sql
        # provide_context ì‚­ì œë¨
    )